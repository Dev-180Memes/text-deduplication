{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSiZV8m5/VADPKGm4zCYYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dev-180Memes/text-deduplication/blob/main/Text_Deduplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FdpfU_3Wj2_K"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory_usage():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  return process.memory_info().rss / 1024 / 1024"
      ],
      "metadata": {
        "id": "jBvn1DK7kDox"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimHash:\n",
        "  def __init__(self, text, hash_size=64):\n",
        "    self.hash_size = hash_size\n",
        "    self.simhash = self._compute_simhash(text)\n",
        "\n",
        "  def _tokenize(self, text):\n",
        "    text = text.lower()\n",
        "    tokens = re.findall(r'\\w+', text)\n",
        "    return tokens\n",
        "\n",
        "  def _hash(self, token):\n",
        "    return int(hashlib.sha1(token.encode('utf-8')).hexdigest(), 16)\n",
        "\n",
        "  def _compute_simhash(self, text):\n",
        "    v = [0] * self.hash_size\n",
        "    tokens = self._tokenize(text)\n",
        "    weights = defaultdict(int)\n",
        "    for token in tokens:\n",
        "      weights[token] += 1\n",
        "\n",
        "    for token, weight in weights.items():\n",
        "      token_hash = self._hash(token)\n",
        "      for i in range(self.hash_size):\n",
        "        bit = (token_hash >> i) & 1\n",
        "        v[i] += weight if bit else -weight\n",
        "\n",
        "    fingerprint = 0\n",
        "    for i in range(self.hash_size):\n",
        "      if v[i] > 0:\n",
        "        fingerprint |= 1 << i\n",
        "    return fingerprint\n",
        "\n",
        "  def hamming_distance(self, other_simhash):\n",
        "    x = self.simhash ^ other_simhash\n",
        "    distance = 0\n",
        "    while x:\n",
        "      distance += x & 1\n",
        "      x >>= 1\n",
        "    return distance"
      ],
      "metadata": {
        "id": "mKvU1xPmkTL7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CDCTTTD:\n",
        "    def __init__(self, text, min_size=64, max_size=256, window_size=48, hash_size=64):\n",
        "        self.min_size = min_size\n",
        "        self.max_size = max_size\n",
        "        self.window_size = window_size\n",
        "        self.hash_size = hash_size\n",
        "        self.fingerprint = self._compute_fingerprint(text)\n",
        "\n",
        "    def _rolling_hash(self, window):\n",
        "        return int(hashlib.md5(window.encode('utf-8')).hexdigest(), 16)\n",
        "\n",
        "    def _chunk_text(self, text):\n",
        "        if len(text) < self.min_size:\n",
        "            return [text.lower()]\n",
        "\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        pos = self.min_size\n",
        "        text = text.lower()  # Normalize case\n",
        "\n",
        "        while pos < len(text):\n",
        "            window = text[max(0, pos-self.window_size):pos]\n",
        "            hash_val = self._rolling_hash(window)\n",
        "\n",
        "            primary_div = 2**13  # 8192\n",
        "            backup_div = 2**11   # 2048\n",
        "\n",
        "            if (pos >= self.min_size and hash_val % primary_div == 0) or \\\n",
        "               (pos >= self.max_size and hash_val % backup_div == 0):\n",
        "                chunks.append(text[start:pos])\n",
        "                start = pos\n",
        "            pos += 1\n",
        "\n",
        "        if start < len(text):\n",
        "            chunks.append(text[start:])\n",
        "        return chunks\n",
        "\n",
        "    def _compute_fingerprint(self, text):\n",
        "        # Create a fingerprint similar to SimHash but based on chunks\n",
        "        v = [0] * self.hash_size\n",
        "        chunks = self._chunk_text(text)\n",
        "\n",
        "        # Weight chunks by their frequency\n",
        "        chunk_weights = defaultdict(int)\n",
        "        for chunk in chunks:\n",
        "            chunk_weights[chunk] += 1\n",
        "\n",
        "        for chunk, weight in chunk_weights.items():\n",
        "            chunk_hash = int(hashlib.sha1(chunk.encode('utf-8')).hexdigest(), 16)\n",
        "            for i in range(self.hash_size):\n",
        "                bit = (chunk_hash >> i) & 1\n",
        "                v[i] += weight if bit else -weight\n",
        "\n",
        "        fingerprint = 0\n",
        "        for i in range(self.hash_size):\n",
        "            if v[i] > 0:\n",
        "                fingerprint |= 1 << i\n",
        "        return fingerprint\n",
        "\n",
        "    def hamming_distance(self, other_fingerprint):\n",
        "        x = self.fingerprint ^ other_fingerprint\n",
        "        distance = 0\n",
        "        while x:\n",
        "            distance += x & 1\n",
        "            x >>= 1\n",
        "        return distance"
      ],
      "metadata": {
        "id": "jWQFWAQqn21T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_deduplication(input_file, output_simhash, output_cdctttd,\n",
        "                         simhash_threshold=3, cdctttd_threshold=3):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "    total_lines = len(lines)\n",
        "    metrics = {\n",
        "        'simhash': {'ratio': 0, 'time': 0, 'memory': 0},\n",
        "        'cdctttd': {'ratio': 0, 'time': 0, 'memory': 0}\n",
        "    }\n",
        "\n",
        "    # SimHash\n",
        "    start_time = time.time()\n",
        "    start_memory = get_memory_usage()\n",
        "    simhash_seen = []\n",
        "    simhash_unique = []\n",
        "    for line in lines:\n",
        "        simhash = SimHash(line)\n",
        "        is_duplicate = False\n",
        "        for seen_hash in simhash_seen:\n",
        "            if simhash.hamming_distance(seen_hash) <= simhash_threshold:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "        if not is_duplicate:\n",
        "            simhash_seen.append(simhash.simhash)\n",
        "            simhash_unique.append(line)\n",
        "\n",
        "    metrics['simhash']['time'] = time.time() - start_time\n",
        "    metrics['simhash']['memory'] = get_memory_usage() - start_memory\n",
        "    metrics['simhash']['ratio'] = (total_lines - len(simhash_unique)) / total_lines if total_lines > 0 else 0\n",
        "\n",
        "    with open(output_simhash, 'w', encoding='utf-8') as f:\n",
        "        f.writelines(line + '\\n' for line in simhash_unique)\n",
        "\n",
        "    # CDC-TTTD\n",
        "    start_time = time.time()\n",
        "    start_memory = get_memory_usage()\n",
        "    cdctttd_seen = []\n",
        "    cdctttd_unique = []\n",
        "    for line in lines:\n",
        "        cdctttd = CDCTTTD(line)\n",
        "        is_duplicate = False\n",
        "        for seen_hash in cdctttd_seen:\n",
        "            if cdctttd.hamming_distance(seen_hash) <= cdctttd_threshold:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "        if not is_duplicate:\n",
        "            cdctttd_seen.append(cdctttd.fingerprint)\n",
        "            cdctttd_unique.append(line)\n",
        "\n",
        "    metrics['cdctttd']['time'] = time.time() - start_time\n",
        "    metrics['cdctttd']['memory'] = get_memory_usage() - start_memory\n",
        "    metrics['cdctttd']['ratio'] = (total_lines - len(cdctttd_unique)) / total_lines if total_lines > 0 else 0\n",
        "\n",
        "    with open(output_cdctttd, 'w', encoding='utf-8') as f:\n",
        "        f.writelines(line + '\\n' for line in cdctttd_unique)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "5kT2-yqPrIOK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'input.txt'\n",
        "output_simhash = 'output_simhash.txt'\n",
        "output_cdctttd = 'output_cdctttd.txt'"
      ],
      "metadata": {
        "id": "jlJnO8ajuhh1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_content = \"\"\"The quick brown fox jumps over the lazy dog\n",
        "    The quick brown fox jumps over the lazy dog\n",
        "    The Quick Brown Fox Jumps Over The Lazy Dog!\n",
        "    The quick brown fox leaps over the idle dog.\n",
        "    A swift brown fox jumps over a resting dog\n",
        "    Completely different content about cats\n",
        "    Rain falls gently on the green meadow\n",
        "    Rain Falls Gently on the Green Meadow\n",
        "    rain falls gently on the green meadow!\n",
        "    Rain drops softly on the verdant field\n",
        "    Sunshine warms the golden hills today\n",
        "    Sunshine warms the golden hills today\n",
        "    SUNSHINE WARMS THE GOLDEN HILLS TODAY\n",
        "    Sunshine heats the yellow slopes now\n",
        "    The old oak tree stands tall\n",
        "    The old oak tree stands tall\n",
        "    the OLD Oak Tree Stands TALL!\n",
        "    The ancient oak tree rises high\n",
        "    Birds sing sweetly in the morning\n",
        "    Birds sing sweetly in the morning\n",
        "    birds SING sweetly in the MORNING\n",
        "    Birds chirp pleasantly at dawn\n",
        "    Quiet rivers flow through the valley\n",
        "    Quiet rivers flow through the valley\n",
        "    QUIET RIVERS FLOW THROUGH THE VALLEY!\n",
        "    Silent streams run across the vale\n",
        "    Snow covers the mountain peaks\n",
        "    Snow covers the mountain peaks\n",
        "    snow COVERS the mountain PEAKS\n",
        "    Frost blankets the high summits\n",
        "    Wind blows across the open plains\n",
        "    Wind blows across the open plains\n",
        "    WIND BLOWS ACROSS THE OPEN PLAINS\n",
        "    Breeze sweeps over the wide fields\n",
        "    Stars shine brightly in the night sky\n",
        "    Stars shine brightly in the night sky\n",
        "    stars SHINE brightly in the NIGHT sky!\n",
        "    Stars glow vividly in the dark heavens\n",
        "    Moonlight dances on the calm lake\n",
        "    Moonlight dances on the calm lake\n",
        "    MOONLIGHT DANCES ON THE CALM LAKE\n",
        "    Moonbeams play on the still water\n",
        "    Children play happily in the park\n",
        "    Children play happily in the park\n",
        "    children PLAY happily in the PARK!\n",
        "    Kids frolic joyfully in the playground\n",
        "    Flowers bloom in the spring garden\n",
        "    Flowers bloom in the spring garden\n",
        "    FLOWERS BLOOM IN THE SPRING GARDEN\n",
        "    Blossoms open in the vernal yard\n",
        "    Thunder rumbles in the distance\n",
        "    Thunder rumbles in the distance\n",
        "    THUNDER RUMBLES IN THE DISTANCE!\n",
        "    Thunder rolls far away\n",
        "    Waves crash against the rocky shore\n",
        "    Waves crash against the rocky shore\n",
        "    waves CRASH against the ROCKY shore\n",
        "    Surf pounds on the stone coast\n",
        "    Total unique content about space travel\n",
        "    Another completely different topic\n",
        "    Yet another distinct subject matter\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pyeF23YTupDj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(input_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(sample_content)"
      ],
      "metadata": {
        "id": "9s0PtXhXut1M"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_deduplication(input_file, output_simhash, output_cdctttd)"
      ],
      "metadata": {
        "id": "MD2PLpDMuw0D"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluation Metrics:\")\n",
        "print(\"\\nSimHash:\")\n",
        "print(f\"Deduplication Ratio: {results['simhash']['ratio']:.2%}\")\n",
        "print(f\"Execution Time: {results['simhash']['time']:.4f} seconds\")\n",
        "print(f\"Memory Utilization: {results['simhash']['memory']:.2f} MB\")\n",
        "\n",
        "print(\"\\nCDC-TTTD:\")\n",
        "print(f\"Deduplication Ratio: {results['cdctttd']['ratio']:.2%}\")\n",
        "print(f\"Execution Time: {results['cdctttd']['time']:.4f} seconds\")\n",
        "print(f\"Memory Utilization: {results['cdctttd']['memory']:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfLhVP7Ju24U",
        "outputId": "366d43b1-0fb5-4dcd-d577-fa89ecdeab3a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "\n",
            "SimHash:\n",
            "Deduplication Ratio: 45.90%\n",
            "Execution Time: 0.0111 seconds\n",
            "Memory Utilization: 0.00 MB\n",
            "\n",
            "CDC-TTTD:\n",
            "Deduplication Ratio: 34.43%\n",
            "Execution Time: 0.0081 seconds\n",
            "Memory Utilization: 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6rnlUDYvfZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}